{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yVx9_Hg-THRx",
        "1Ob1yNDvWi_t"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonderfulOblivion/ML-practice/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# МЛ Практика 3: Подбор признаков и валидация моделей"
      ],
      "metadata": {
        "id": "GC05BxsGIBQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Цель занятия:**\n",
        "Изучить методы поиска значимых признаков в данных. На практике мы проведем анализ целевой переменной **Y**, применим методы для поиска значимых признаков, обучим линейную модель, проанализируем результат и оценим валидность модели.\n",
        "\n",
        "## **Задание состоит из следующих частей:**\n",
        "1. Обработка выбросов;\n",
        "1. Поиск значимых признаков с использованием библиотеки **sklearn**.\n",
        "2. Обучение логистической регресси модели и оценка ее точности.\n",
        "6. Кросс-валидация с использованием разных методов (K-fold, ShuffleSplit, test-train-validation)"
      ],
      "metadata": {
        "id": "MlKCXJoPIWJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: Загрузка библиотек и предобратка данных"
      ],
      "metadata": {
        "id": "2UOXANO8MiXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2j-haNH5Z4",
        "outputId": "cb185d07-61c7-434e-f1b7-522fd8888292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn seaborn scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel"
      ],
      "metadata": {
        "id": "Oe38ZbZ4Inh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка набора данных\n",
        "df = pd.read_csv('/content/employee.csv')"
      ],
      "metadata": {
        "id": "fRPcfkb4Irha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "zTOX9_sIItK3",
        "outputId": "c84baf73-20f8-4856-830d-5a842a318893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       satisfaction_level  last_evaluation  number_project  \\\n",
              "0                    0.38             0.53               2   \n",
              "1                    0.80             0.86               5   \n",
              "2                    0.11             0.88               7   \n",
              "3                    0.72             0.87               5   \n",
              "4                    0.37             0.52               2   \n",
              "...                   ...              ...             ...   \n",
              "14994                0.40             0.57               2   \n",
              "14995                0.37             0.48               2   \n",
              "14996                0.37             0.53               2   \n",
              "14997                0.11             0.96               6   \n",
              "14998                0.37             0.52               2   \n",
              "\n",
              "       average_montly_hours  time_spend_company  Work_accident  \\\n",
              "0                       157                   3              0   \n",
              "1                       262                   6              0   \n",
              "2                       272                   4              0   \n",
              "3                       223                   5              0   \n",
              "4                       159                   3              0   \n",
              "...                     ...                 ...            ...   \n",
              "14994                   151                   3              0   \n",
              "14995                   160                   3              0   \n",
              "14996                   143                   3              0   \n",
              "14997                   280                   4              0   \n",
              "14998                   158                   3              0   \n",
              "\n",
              "       promotion_last_5years department  salary  left  \n",
              "0                          0      sales     low     1  \n",
              "1                          0      sales  medium     1  \n",
              "2                          0      sales  medium     1  \n",
              "3                          0      sales     low     1  \n",
              "4                          0      sales     low     1  \n",
              "...                      ...        ...     ...   ...  \n",
              "14994                      0    support     low     1  \n",
              "14995                      0    support     low     1  \n",
              "14996                      0    support     low     1  \n",
              "14997                      0    support     low     1  \n",
              "14998                      0    support     low     1  \n",
              "\n",
              "[14999 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b1378eb-456d-48f1-85b6-3a2a5509ea6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>satisfaction_level</th>\n",
              "      <th>last_evaluation</th>\n",
              "      <th>number_project</th>\n",
              "      <th>average_montly_hours</th>\n",
              "      <th>time_spend_company</th>\n",
              "      <th>Work_accident</th>\n",
              "      <th>promotion_last_5years</th>\n",
              "      <th>department</th>\n",
              "      <th>salary</th>\n",
              "      <th>left</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>5</td>\n",
              "      <td>262</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.88</td>\n",
              "      <td>7</td>\n",
              "      <td>272</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.87</td>\n",
              "      <td>5</td>\n",
              "      <td>223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>159</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14994</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.57</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>support</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.48</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>support</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>143</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>support</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.96</td>\n",
              "      <td>6</td>\n",
              "      <td>280</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>support</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>158</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>support</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14999 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b1378eb-456d-48f1-85b6-3a2a5509ea6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b1378eb-456d-48f1-85b6-3a2a5509ea6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b1378eb-456d-48f1-85b6-3a2a5509ea6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-654c3350-f7d1-407b-8947-b2cf06da96e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-654c3350-f7d1-407b-8947-b2cf06da96e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-654c3350-f7d1-407b-8947-b2cf06da96e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14999,\n  \"fields\": [\n    {\n      \"column\": \"satisfaction_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2486306510611418,\n        \"min\": 0.09,\n        \"max\": 1.0,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          0.83,\n          0.13,\n          0.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_evaluation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17116911062327592,\n        \"min\": 0.36,\n        \"max\": 1.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.66,\n          0.44,\n          0.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_project\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_montly_hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 96,\n        \"max\": 310,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          118,\n          112,\n          222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_spend_company\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6,\n          8,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Work_accident\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"promotion_last_5years\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"marketing\",\n          \"accounting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"low\",\n          \"medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"left\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_best_employee'] = np.where(df['average_montly_hours'] >= 7, 1, 0)\n",
        "df.is_best_employee = df.is_best_employee.astype('category')\n",
        "df[-'type'] = df['type'].astype('category')"
      ],
      "metadata": {
        "id": "nRQCx58BIx35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "a1702850-3a91-4667-ef03-bae61744fefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'type'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8f7bf861d413>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_best_employee'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_montly_hours'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_best_employee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_best_employee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['is_best_wine'] # выбираем целевую переменную (категориальную)\n",
        "X = df.drop('is_best_wine', axis=1) # переменные для проверки влияния\n",
        "\n",
        "# В моем случае я дропаю базовую переменную, а не только. Y\n",
        "X = X.drop('quality', axis=1)"
      ],
      "metadata": {
        "id": "K6jhJwjII4Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('quality', axis=1).info()"
      ],
      "metadata": {
        "id": "T_ENswCSI6Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gHfYJGB5LSW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: масштабирование признаков"
      ],
      "metadata": {
        "id": "ITt-cRGOMoci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "ltewiHkMM9xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем копию данных\n",
        "X_processed = X.copy()\n",
        "\n",
        "category_columns: list[str] = X_processed.select_dtypes(include=['category']).columns # собираем колонки помеченные как category\n",
        "\n",
        "# Применяем One-Hot Encoding\n",
        "X_processed = pd.get_dummies(X_processed, columns=category_columns,drop_first=True) # drop_first=True позволяет избежать мультиколлинеарности, удаляя первый уровень категориальной переменной.\n"
      ],
      "metadata": {
        "id": "_xrNg192Mrbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed"
      ],
      "metadata": {
        "id": "068YgLUYNY5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбираем числовые признаки\n",
        "numeric_features = X_processed.select_dtypes(include=['float64']).columns.tolist()\n",
        "\n",
        "# Инициализируем scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Применяем нормализацию\n",
        "X_processed[numeric_features] = scaler.fit_transform(X_processed[numeric_features])\n"
      ],
      "metadata": {
        "id": "ycYmWaDKNkb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed"
      ],
      "metadata": {
        "id": "HfPr7IG-Nnkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Очистка данных и удаление выбросов"
      ],
      "metadata": {
        "id": "OEwbqT5xN46N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Важным шагом в машинном обучении - является очистка и удаление данных от выбросов."
      ],
      "metadata": {
        "id": "w_RhTMhfN7KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Методы обработки выбросов:\n",
        "\n",
        "1. **Метод на основе медианы и межквартильного размаха (IQR)**:\n",
        "   - **Как работает**:\n",
        "     Метод основан на расчете межквартильного размаха (IQR), который вычисляется как разница между третьим (75-й перцентиль) и первым квартилем (25-й перцентиль). Данные считаются выбросами, если они выходят за пределы диапазона \\([Q1 - 1.5 * IQR , Q3 + 1.5 * IQR]\\).\n",
        "   - **Зачем это нужно**:\n",
        "     Выбросы могут серьезно искажать результаты моделей, особенно тех, которые основаны на средних значениях или предполагают нормальное распределение данных.\n",
        "   - **Когда лучше использовать**:\n",
        "     - Когда данные содержат **немного выбросов** и имеют **асимметричное распределение**.\n",
        "     - Метод медианы и IQR более устойчив к выбросам по сравнению с методом, основанным на среднем значении, так как медиана меньше подвержена влиянию экстремальных значений.\n",
        "     - Хорошо подходит для набора данных, которые не распределены нормально (например, зарплаты или цены на недвижимость).\n",
        "\n",
        "2. **Метод на основе среднего (Mean)**:\n",
        "   - **Как работает**:\n",
        "     Метод использует средние значения и удаляет те признаки или записи, которые значительно отклоняются от среднего. Чаще всего это делается с помощью установления порога (например, данные, которые превышают 2 или 3 средних значения, считаются выбросами).\n",
        "   - **Зачем это нужно**:\n",
        "     Выбросы, сильно отличающиеся от средних значений, могут существенно влиять на такие модели, как линейная регрессия, так как среднее значение сильно чувствительно к экстремальным точкам.\n",
        "   - **Когда лучше использовать**:\n",
        "     - Когда данные имеют **нормальное распределение** или приближены к нормальному.\n",
        "     - Подходит, если данные содержат **много выбросов**, и вам нужно жестче ограничить их влияние на модель.\n",
        "\n",
        "### Как выбрать метод:\n",
        "\n",
        "- **Если данные асимметричны** или распределены с \"хвостами\" (например, распределение доходов или цен), лучше использовать **метод на основе медианы и IQR**, так как медиана не чувствительна к выбросам и лучше описывает такие наборы данных.\n",
        "  \n",
        "- **Если данные нормально распределены** и важно учитывать всю выборку, даже если есть выбросы, можно использовать **метод на основе среднего**. Этот метод будет точнее отражать центр распределения в симметричных данных и позволит выявить значительные отклонения от него.\n",
        "\n",
        "Оба метода помогают улучшить производительность моделей машинного обучения, обеспечивая более точное представление данных для анализа и обучения."
      ],
      "metadata": {
        "id": "_LeUY3VtWKZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Для начала определеим функцию обучения с оценкой качества (для простоты)"
      ],
      "metadata": {
        "id": "I4nUsq9hS8Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def train_and_evaluate(X, Y):\n",
        "    # Разделение данных на обучающую и тестовую выборки\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "\n",
        "    # Инициализация модели\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Обучение модели\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Предсказания на обучающей выборке\n",
        "    Y_train_pred = model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
        "\n",
        "    # Предсказания на тестовой выборке\n",
        "    Y_test_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
        "\n",
        "    # Вывод результатов\n",
        "    print(f\"Точность на обучающей выборке: {train_accuracy:.4f}\")\n",
        "    print(f\"Точность на тестовой выборке: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Классификационный отчет\n",
        "    print(\"\\nКлассификационный отчет на тестовой выборке:\")\n",
        "    print(classification_report(Y_test, Y_test_pred))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "O3bsgG6TN6rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(X_processed, Y)"
      ],
      "metadata": {
        "id": "UJB6moFZT6sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метод 1: удаление на основе медианы"
      ],
      "metadata": {
        "id": "yVx9_Hg-THRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h8Ra2980VnUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для удаления выбросов на основе межквартильного размаха (1.5 IQR)\n",
        "def remove_outliers_based_on_iqr(X, y, iqr_multiplier=1.5):\n",
        "    # Убедимся, что работаем только с числовыми данными\n",
        "    X_numeric = X.select_dtypes(include=['number'])\n",
        "\n",
        "    # Рассчитываем первый и третий квартили для каждой числовой переменной\n",
        "    Q1 = X_numeric.quantile(0.25)\n",
        "    Q3 = X_numeric.quantile(0.75)\n",
        "\n",
        "    # Вычисляем межквартильный размах (IQR)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Оставляем только те значения, которые находятся в диапазоне [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
        "    X_filtered = X_numeric[~((X_numeric < (Q1 - iqr_multiplier * IQR)) | (X_numeric > (Q3 + iqr_multiplier * IQR))).any(axis=1)]\n",
        "\n",
        "    # Синхронизируем y с отфильтрованными X\n",
        "    y_filtered = y.loc[X_filtered.index]\n",
        "\n",
        "    return X_filtered, y_filtered\n"
      ],
      "metadata": {
        "id": "UFF2F2aETHBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_iqr, y_iqr = remove_outliers_based_on_iqr(X_processed, Y, iqr_multiplier=3)"
      ],
      "metadata": {
        "id": "e2wE79s3N2Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed.describe()"
      ],
      "metadata": {
        "id": "ynUzhuqgUyVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_iqr.describe()"
      ],
      "metadata": {
        "id": "HX-L59jgUvio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_gS3Z3cMe0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(X_iqr, y_iqr)"
      ],
      "metadata": {
        "id": "KLIApZxYU1UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Провести анализ выводов, посмотреть как измеились переменные и описать результат**"
      ],
      "metadata": {
        "id": "XOxbQhQRWozB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метод 2: удаление на основе среднего"
      ],
      "metadata": {
        "id": "1Ob1yNDvWi_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для удаления выбросов на основе среднего значения\n",
        "\n",
        "def remove_outliers_based_on_mean(X, y, mean_multiplier=2):\n",
        "    # Убедимся, что работаем только с числовыми данными\n",
        "    X_numeric = X.select_dtypes(include=['number'])\n",
        "\n",
        "    # Рассчитываем среднее значение и стандартное отклонение для каждой переменной\n",
        "    mean_values = X_numeric.mean()\n",
        "    std_values = X_numeric.std()\n",
        "\n",
        "    # Устанавливаем верхний и нижний пороги на основе среднего значения и множителя стандартного отклонения\n",
        "    lower_threshold = mean_values - mean_multiplier * std_values\n",
        "    upper_threshold = mean_values + mean_multiplier * std_values\n",
        "\n",
        "    # Фильтруем наблюдения, которые находятся в пределах этих порогов по всем признакам\n",
        "    X_filtered = X_numeric[~((X_numeric < lower_threshold) | (X_numeric > upper_threshold)).any(axis=1)]\n",
        "\n",
        "    # Синхронизируем y с отфильтрованными X\n",
        "    y_filtered = y.loc[X_filtered.index]\n",
        "\n",
        "    return X_filtered, y_filtered"
      ],
      "metadata": {
        "id": "-w_aMdPrU_ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean, y_mean = remove_outliers_based_on_mean(X_processed.copy(), Y.copy())"
      ],
      "metadata": {
        "id": "v6-GxQvtMeSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed.describe()"
      ],
      "metadata": {
        "id": "PgI5xTe5MRJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean.describe()"
      ],
      "metadata": {
        "id": "ZJHQELdNLTuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(X_mean, y_mean)"
      ],
      "metadata": {
        "id": "5eFTjr-7VeNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Провести анализ выводов, посмотреть как измеились переменные и описать результат**"
      ],
      "metadata": {
        "id": "PNIgmKrOWsJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Методы отбора признаков"
      ],
      "metadata": {
        "id": "ZDcU3fYXgMXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отбор признаков (feature selection) — важный шаг в машинном обучении, который помогает улучшить качество моделей и ускорить их работу. Цель отбора — убрать лишние или малозначимые признаки, которые не влияют на предсказания модели, либо могут ухудшить её производительность.\n",
        "\n",
        "Зачем это нужно:\n",
        "1. **Улучшение производительности модели** — избыточные признаки могут создавать шум и снижать точность.\n",
        "2. **Повышение интерпретируемости** — меньший набор признаков легче анализировать и объяснять.\n",
        "3. **Снижение вычислительной сложности** — меньшее количество признаков ускоряет обучение и предсказание.\n",
        "\n",
        "В sklearn основные методы отбора признаков включают:\n",
        "1. **Filter методы** — основаны на статистических тестах, например, `SelectKBest` использует критерий, чтобы выбрать признаки с наибольшим вкладом.\n",
        "2. **Wrapper методы** — оценивают модели на разных подмножествах признаков, например, рекурсивное исключение признаков (`RFE`).\n",
        "3. **Embedded методы** — выполняют отбор признаков во время обучения модели, например, с помощью L1-регуляризации (Lasso)."
      ],
      "metadata": {
        "id": "F677-0HNgXZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter методы"
      ],
      "metadata": {
        "id": "ITLFA6akiNbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter методы основаны на статистических свойствах данных и выбирают признаки, не учитывая алгоритм машинного обучения. Они работают как предварительный шаг перед обучением модели и быстро отбирают наиболее информативные признаки.\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "- Быстро выполняются.\n",
        "- Не зависят от модели.\n",
        "- Уменьшают размерность данных до обучения.\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "- Не учитывают взаимодействие между признаками.\n",
        "- Могут упускать важные комбинации признаков."
      ],
      "metadata": {
        "id": "EVVPANUIiPBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n"
      ],
      "metadata": {
        "id": "jCi6QZFxiXMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем SelectKBest для выбора 5 лучших признаков\n",
        "selector = SelectKBest(score_func=f_regression, k=5)\n",
        "X_kbest = selector.fit_transform(X_processed, Y)\n"
      ],
      "metadata": {
        "id": "JYEvYCmUibZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector.scores_"
      ],
      "metadata": {
        "id": "ZC6VMzkCNfaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed.columns"
      ],
      "metadata": {
        "id": "opAcRKcWOAk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed"
      ],
      "metadata": {
        "id": "OkKUMTWUNamj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏰ Изучите 1 из методов и используйте его как score_func (Важно учитывать, что не все методы могут подходить под тип признака, например chi2 подходит только для категориальных)\n",
        "\n",
        "```**P.S. методы работают по разному для дискретных и непрерывных значений. Методы необходимо использовать для своих типов переменных!**```\n",
        "\n",
        "[link](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "\n",
        "**f_classif**: ANOVA F-value between label/feature for classification tasks.\n",
        "\n",
        "**mutual_info_classif**: Mutual information for a discrete target.\n",
        "\n",
        "**chi2**: Chi-squared stats of non-negative features for classification tasks.\n",
        "\n",
        "**f_regression**: F-value between label/feature for regression tasks.\n",
        "\n",
        "**mutual_info_regression**: Mutual information for a continuous target.\n",
        "\n",
        "**SelectPercentile**: Select features based on percentile of the highest scores.\n",
        "\n",
        "**SelectFpr**: Select features based on a false positive rate test.\n",
        "\n",
        "**SelectFdr**: Select features based on an estimated false discovery rate.\n",
        "\n",
        "**SelectFwe**: Select features based on family-wise error rate.\n",
        "\n",
        "**GenericUnivariateSelect**: Univariate feature selector with configurable mode."
      ],
      "metadata": {
        "id": "3d9c_ckPu-l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selector.get_support(indices=True)"
      ],
      "metadata": {
        "id": "vhIWJANlifGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем список отобранных признаков\n",
        "selected_features = X_processed.columns[selector.get_support(indices=True)]\n",
        "print(\"Отобранные признаки:\", selected_features)"
      ],
      "metadata": {
        "id": "bnXnyAZNicPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем X_kbest в DataFrame\n",
        "X_kbest_df = pd.DataFrame(X_kbest, columns=selected_features)\n",
        "\n",
        "# Обучаем и оцениваем модель\n",
        "train_and_evaluate(X_kbest_df, Y)"
      ],
      "metadata": {
        "id": "rxcgTPJlil8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper методы"
      ],
      "metadata": {
        "id": "ROb2c0yBivBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrapper методы оценивают различные комбинации признаков, обучая модель на каждом подмножестве, и выбирают набор признаков, который дает наилучшее качество модели. Они учитывают взаимодействия между признаками, но могут быть вычислительно затратными.\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "- Учитывают взаимодействия между признаками.\n",
        "- Могут улучшить производительность модели.\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "- Высокая вычислительная сложность.\n",
        "- Длительное время выполнения на больших наборах данных."
      ],
      "metadata": {
        "id": "9N3Y9dPLiz74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Инициализируем модель логистической регрессии\n",
        "base_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Инициализируем RFE для выбора 5 лучших признаков\n",
        "rfe = RFE(estimator=base_model, n_features_to_select=5)\n",
        "rfe.fit(X_processed, Y)\n",
        "\n",
        "# Получаем список отобранных признаков\n",
        "selected_features = X_processed.columns[rfe.support_]\n",
        "print(\"Отобранные признаки:\", selected_features)\n"
      ],
      "metadata": {
        "id": "1xD6Oy-di4YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Отбираем признаки\n",
        "X_rfe = X_processed[selected_features]\n",
        "\n",
        "# Обучаем и оцениваем модель\n",
        "model = train_and_evaluate(X_rfe, Y)\n"
      ],
      "metadata": {
        "id": "mJI82lCQi-Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedded методы"
      ],
      "metadata": {
        "id": "QhRhn9zNjGoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преимущества:\n",
        "\n",
        "Учитывают взаимодействия между признаками.\n",
        "- Менее вычислительно затратны, чем Wrapper методы.\n",
        "- Интегрированы в процесс обучения.\n",
        "Недостатки:\n",
        "\n",
        "- Зависимы от выбранной модели.\n",
        "- Могут не отбирать признаки, важные для других моделей."
      ],
      "metadata": {
        "id": "ZwbLSrT6jHls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Обучаем модель без регуляризации\n",
        "model_no_penalty = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "model_no_penalty.fit(X_processed, Y)\n",
        "\n",
        "# Выводим коэффициенты модели без регуляризации\n",
        "coefficients_no_penalty = model_no_penalty.coef_\n",
        "print(\"Коэффициенты модели без регуляризации:\", coefficients_no_penalty)\n",
        "\n",
        "# Инициализируем модель с L1-регуляризацией\n",
        "model_with_penalty = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Обучаем модель с регуляризацией\n",
        "model_with_penalty.fit(X_processed, Y)\n",
        "\n",
        "# Выводим коэффициенты модели с регуляризацией\n",
        "coefficients_with_penalty = model_with_penalty.coef_\n",
        "print(\"Коэффициенты модели с регуляризацией:\", coefficients_with_penalty)\n",
        "\n",
        "# Используем SelectFromModel для отбора признаков\n",
        "selector = SelectFromModel(model_with_penalty, prefit=True)\n",
        "X_embedded = selector.transform(X_processed)\n",
        "\n",
        "# Получаем список отобранных признаков\n",
        "selected_features = X_processed.columns[selector.get_support()]\n",
        "print(\"Отобранные признаки:\", selected_features)\n",
        "\n",
        "# Обучаем модель на отобранных признаках\n",
        "model_embedded = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "model_embedded.fit(X_embedded, Y)\n",
        "\n",
        "# Выводим коэффициенты модели после отбора признаков\n",
        "coefficients_embedded = model_embedded.coef_\n",
        "print(\"Коэффициенты модели после отбора признаков:\", coefficients_embedded)\n",
        "\n",
        "# Визуализация коэффициентов моделей\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Коэффициенты модели без регуляризации\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(coefficients_no_penalty[0])), coefficients_no_penalty[0])\n",
        "plt.title(\"Коэффициенты модели без регуляризации\")\n",
        "plt.xlabel(\"Признаки\")\n",
        "plt.ylabel(\"Значение коэффициента\")\n",
        "\n",
        "# Коэффициенты модели с регуляризацией\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(coefficients_with_penalty[0])), coefficients_with_penalty[0])\n",
        "plt.title(\"Коэффициенты модели с регуляризацией\")\n",
        "plt.xlabel(\"Признаки\")\n",
        "plt.ylabel(\"Значение коэффициента\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2SZ-2-_njMCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем X_embedded в DataFrame\n",
        "X_embedded_df = pd.DataFrame(X_embedded, columns=selected_features)\n",
        "\n",
        "# Обучаем и оцениваем модель\n",
        "model = train_and_evaluate(X_embedded_df, Y)\n"
      ],
      "metadata": {
        "id": "a_T9oI8yjRFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Проэксперементировать с разным количеством k, найти лучшую модель, объяснить результат**"
      ],
      "metadata": {
        "id": "LFI5U8UCjoNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Изучить метод отбора ```SequentialFeatureSelector```, описать способ работы, сравнить результат с прошлыми методами и объяснить полученный результат**"
      ],
      "metadata": {
        "id": "jMEfymkXkV6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Логистическая регрессия"
      ],
      "metadata": {
        "id": "Le161QmGmDVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Логистическая регрессия** — это модель для задач бинарной классификации, которая предсказывает вероятность того, что наблюдение принадлежит к одному из двух классов (например, 0 или 1). Модель основана на линейной регрессии, но использует **сигмоидную функцию активации** для приведения предсказаний в диапазон от 0 до 1. Логистическая регрессия идеально подходит для задач, где нужно классифицировать данные на два класса.\n"
      ],
      "metadata": {
        "id": "ZMPvfmg_mGF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Принцип работы логистической регрессии:\n",
        "1. Сначала вычисляется линейная комбинация признаков с весами:  \n",
        "y = b + w1 * x1 + w2 * x2 + w(n) * x(n), где\n",
        "\n",
        "x - переменные\n",
        "\n",
        "w - веса (коэфициенты регресси)\n",
        "\n",
        "b - смещение\n",
        "\n",
        "Затем результат линейной комбинации передается в сигмоидную функцию активации, которая преобразует результат в значение от 0 до 1."
      ],
      "metadata": {
        "id": "wEeLOG9VmIzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция активации (Сигмоида)\n",
        "**Сигмоидная функция** в логистической регрессии используется для преобразования линейной комбинации признаков в вероятность, что наблюдение относится к классу 1. Формула сигмоиды:\n",
        "\n",
        "sigmoida = 1 / (1 + e^-y)\n",
        "\n",
        "Она всегда возвращает значение в диапазоне от 0 до 1, что удобно для интерпретации как вероятность принадлежности к классу 1."
      ],
      "metadata": {
        "id": "l14i_bHXmp4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Принцип работы:\n",
        "1. Инициализация весов: Изначально все веса устанавливаются в нули.\n",
        "\n",
        "2. Градиентный спуск: На каждой итерации:\n",
        "- Вычисляется линейная комбинация признаков.\n",
        "- Применяется сигмоидная функция для предсказания вероятностей.\n",
        "- Градиенты вычисляются для обновления весов и смещения, минимизируя ошибку.\n",
        "\n",
        "Предсказание: Для новых данных модель возвращает вероятность, которая затем конвертируется в классы 0 или 1."
      ],
      "metadata": {
        "id": "pixEZ_AIqX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Сигмоидная функция\n",
        "def sigmoid(z):\n",
        "    # Убедимся, что z это numpy массив\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Простая реализация логистической регрессии\n",
        "class OwnLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "\n",
        "    # Метод для обучения модели\n",
        "    def fit(self, X, y):\n",
        "        # Инициализация весов\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for idx_,_ in enumerate(range(self.iterations)):\n",
        "            # Линейная комбинация\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            # Применяем сигмоиду для предсказания\n",
        "            y_pred = sigmoid(linear_model)\n",
        "\n",
        "            # Вычисляем градиенты\n",
        "            dw = (1 / len(X)) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / len(X)) * np.sum(y_pred - y)\n",
        "\n",
        "            # Обновляем веса и смещение\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    # Метод для предсказания\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        print(\"regression\",linear_model)\n",
        "        y_pred = sigmoid(linear_model)\n",
        "        print(\"sigmoid\",y_pred)\n",
        "        # Возвращаем метки классов (0 или 1)\n",
        "        return [1 if i > 0.5 else 0 for i in y_pred]\n"
      ],
      "metadata": {
        "id": "vLzS8KaQm9Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "X = np.array([[0.1, 1.2], [1.1, 2.2], [2.1, 1.9], [1.0, 1.0]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "model = OwnLogisticRegression(learning_rate=0.1, iterations=1000)\n",
        "model.fit(X, y)\n",
        "predictions = model.predict(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "h4Ri-FIsopcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ Вопрос о принципе работы регресси будет в первом теоретическом модуле, важно понимание как оно работает"
      ],
      "metadata": {
        "id": "yc7QC1GNqsE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Кросс-валидация"
      ],
      "metadata": {
        "id": "Hjmb7k8IkN4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Кросс-валидация** — это метод оценки качества моделей машинного обучения, который помогает избежать переобучения и получить более надежную оценку. Она заключается в разделении данных на несколько частей и обучении модели на различных подмножествах данных, чтобы проверить ее способность обобщать на новых данных.\n",
        "\n",
        "Основные цели кросс-валидации:\n",
        "\n",
        "Проверить, насколько хорошо модель будет работать на новых данных.\n",
        "Определить, есть ли у модели проблемы с переобучением (overfitting) или недообучением (underfitting).\n",
        "Помочь выбрать наилучшую модель или гиперпараметры."
      ],
      "metadata": {
        "id": "B0OKYUy4rGuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Виды кросс-валидации\n",
        "1. K-fold Cross-Validation:\n",
        "\n",
        "Данные делятся на K равных частей (folds). Модель обучается на K-1 частях и тестируется на оставшейся части. Процесс повторяется K раз, и результат — среднее качество по всем K итерациям.\n",
        "Этот метод позволяет эффективно использовать все данные как для обучения, так и для тестирования.\n",
        "\n",
        "2. ShuffleSplit:\n",
        "\n",
        "Этот метод несколько раз случайно перемешивает данные и делит их на тренировочные и тестовые выборки. В отличие от K-fold, здесь нет необходимости в разделении на фиксированное количество частей.\n",
        "Хорошо работает на небольших выборках данных и для оценки стабильности модели.\n",
        "\n",
        "3. Train-Test-Validation Split:\n",
        "\n",
        "Данные делятся на три части: тренировочные данные для обучения модели, тестовые данные для первичной оценки и валидационные данные для окончательной оценки.\n",
        "Полезен для задач, где требуется как тестирование, так и финальная проверка на отложенных данных."
      ],
      "metadata": {
        "id": "4A25y-88rRs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, ShuffleSplit, train_test_split, cross_val_score"
      ],
      "metadata": {
        "id": "lLuGz2PSrg26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross-Validation\n",
        "def k_fold_cross_validation(X, y, n_splits=5):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    # Реализация K-Fold вручную\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Обучение модели на тренировочной выборке\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Предсказания на тестовой выборке\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Оценка точности\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    # Выводим среднюю точность и точности по каждому фолду\n",
        "    print(f\"K-Fold Cross-Validation - Средняя точность: {np.mean(accuracies)}\")\n",
        "    print(f\"Точности по каждому фолду: {accuracies}\")\n",
        "\n",
        "# Пример использования:\n",
        "k_fold_cross_validation(X = X_processed.to_numpy(), y = Y.to_numpy())\n"
      ],
      "metadata": {
        "id": "QCY4tf2CrkYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Используем результат отбора признаков (выбираем по наилучшей точности), делаем кросс валидацию и объясняем результат + перебираем параметры n_splits**"
      ],
      "metadata": {
        "id": "hkhEZpGDtKEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ShuffleSplit Cross-Validation\n",
        "def shuffle_split_cross_validation(X, y, n_splits=5, test_size=0.4):\n",
        "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
        "    accuracies = []\n",
        "\n",
        "    # Реализация ShuffleSplit вручную\n",
        "    for train_index, test_index in ss.split(X):\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Обучение модели на тренировочной выборке\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Предсказания на тестовой выборке\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Оценка точности\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    # Выводим среднюю точность и точности по каждому разделению\n",
        "    print(f\"ShuffleSplit Cross-Validation - Средняя точность: {np.mean(accuracies)}\")\n",
        "    print(f\"Точности по каждому разделению: {accuracies}\")\n",
        "\n",
        "# Пример использования:\n",
        "shuffle_split_cross_validation(X_processed.to_numpy(), Y.to_numpy())\n"
      ],
      "metadata": {
        "id": "QcrxEO15sgaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Используем результат отсечения выбросов, делаем кросс валидацию и объясняем результат + перебираем параметры n_splits**"
      ],
      "metadata": {
        "id": "LncO4Mp3th91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test-Validation Split\n",
        "def train_test_validation_split(X, y):\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    # Разделяем данные на тренировочные и оставшиеся (валидация + тест)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Разделяем оставшиеся данные на валидационные и тестовые\n",
        "    X_train_train, X_test, y_train_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Обучаем модель на тренировочных данных\n",
        "    model.fit(X_train_train, y_train_train)\n",
        "\n",
        "    # Оцениваем на валидационных данных\n",
        "    y_valid_pred = model.predict(X_validation)\n",
        "    validation_accuracy = accuracy_score(y_validation, y_valid_pred)\n",
        "    print(f\"Точность на валидационных данных: {validation_accuracy}\")\n",
        "\n",
        "    # Оцениваем на тестовых данных\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    print(f\"Точность на тестовых данных: {test_accuracy}\")\n",
        "\n",
        "# Пример использования:\n",
        "train_test_validation_split(X_processed.to_numpy(), Y.to_numpy())\n"
      ],
      "metadata": {
        "id": "TlPHy51Ore3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Используем результат отсечения выбросов или лучший отбор признаков, делаем кросс валидацию и объясняем результат + перебираем параметры n_splits**"
      ],
      "metadata": {
        "id": "m8g3jBAwt_YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Когда использовать каждый метод:\n",
        "- K-fold Cross-Validation: Отлично подходит для более точной оценки модели, особенно на небольших наборах данных. Используется, когда нужно получить стабильную оценку по всем данным.\n",
        "\n",
        "- ShuffleSplit Cross-Validation: Хорошо работает на небольших выборках, где нужно много раз случайно перемешивать и проверять модель. Это может помочь увидеть, как модель работает на различных случайных подвыборках данных.\n",
        "\n",
        "- Train-Test-Validation Split: Используется, когда нужно четко разделить данные для обучения, подбора параметров и финальной оценки. Подходит для больших наборов данных, где важно иметь отложенную тестовую выборку для окончательной проверки."
      ],
      "metadata": {
        "id": "NQ84DbKkuFl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏰ **Объяснить, какой из методов подходит для вашего датасета**"
      ],
      "metadata": {
        "id": "OoFNv0XNuMm6"
      }
    }
  ]
}